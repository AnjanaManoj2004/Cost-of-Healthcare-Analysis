{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0544b93-9944-446a-a598-7c0a5950dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive modelling on AHPF outcomes data\n",
    "# (readable, step-by-step version)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# ---------- Setup ----------\n",
    "CANDIDATES = [\n",
    "    Path(\"ahpf_outcomes_clean.csv\"),\n",
    "    Path(\"data/anjana/processed/ahpf_outcomes_clean.csv\"),\n",
    "    Path.cwd() / \"ahpf_outcomes_clean.csv\",\n",
    "]\n",
    "AHPF_FILE = next((p for p in CANDIDATES if p.exists()), None)\n",
    "if AHPF_FILE is None:\n",
    "    raise FileNotFoundError(\"Couldn’t find 'ahpf_outcomes_clean.csv'. \"\n",
    "                            \"Place it next to the notebook or under data/anjana/processed/.\")\n",
    "\n",
    "print(\"Using file:\", AHPF_FILE)\n",
    "\n",
    "OUT_DIR = Path(\"outputs/models\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Choose which outcome to predict \n",
    "TARGET = \"Infant and young child mortality rate\"\n",
    "# How many past years of the target to use as features\n",
    "LAGS = [1, 2]\n",
    "\n",
    "#1) Load & basic clean \n",
    "df = pd.read_csv(AHPF_FILE, low_memory=False)\n",
    "df[\"Name\"]  = df[\"Name\"].astype(str).str.strip()\n",
    "df[\"State\"] = df[\"State\"].astype(str).str.strip()\n",
    "df[\"Year\"]  = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Make sure Value is numeric even if it came in with commas or unicode minus signs\n",
    "df[\"Value\"] = (\n",
    "    df[\"Value\"].astype(str)\n",
    "      .str.replace(\",\", \"\", regex=False)\n",
    "      .str.replace(\"\\u2212\", \"-\", regex=False)\n",
    "      .str.extract(r\"([-+]?\\d*\\.?\\d+(e[-+]?\\d+)?)\", expand=False)[0]\n",
    "      .astype(float)\n",
    ")\n",
    "\n",
    "# Keep only rows we can actually model with\n",
    "df = df.dropna(subset=[\"State\", \"Year\", \"Name\", \"Value\"])\n",
    "\n",
    "# Prefer rate/percentage style measures over raw counts (keeps the target scale consistent)\n",
    "rate_like = {\"DecimalOne\", \"DecimalZero\", \"PercentageOne\", \"Proportion\", \"Rate\"}\n",
    "if \"UnitType\" in df.columns:\n",
    "    df = df[df[\"UnitType\"].isin(rate_like)]\n",
    "\n",
    "# 2) Make a panel: rows = (State, Year), columns = indicators\n",
    "wide = (\n",
    "    df.pivot_table(index=[\"State\", \"Year\"], columns=\"Name\", values=\"Value\", aggfunc=\"mean\")\n",
    "      .sort_index()\n",
    "      .dropna(axis=1, how=\"all\")\n",
    ")\n",
    "\n",
    "if TARGET not in wide.columns:\n",
    "    print(\"A few example columns:\", list(wide.columns[:15]))\n",
    "    raise ValueError(f\"Target '{TARGET}' not found. Double-check the exact 'Name' text in your CSV.\")\n",
    "\n",
    "# 3) Add lag features for the target (per state)\n",
    "def add_lags(panel, cols, lag_years):\n",
    "    out = panel.copy()\n",
    "    for col in cols:\n",
    "        for k in lag_years:\n",
    "            out[f\"{col}_lag{k}\"] = out.groupby(level=0)[col].shift(k)\n",
    "    return out\n",
    "\n",
    "wide_lag = add_lags(wide, [TARGET], LAGS)\n",
    "\n",
    "#  4) Train/test split that respects time \n",
    "years = wide_lag.index.get_level_values(\"Year\").unique().sort_values()\n",
    "if len(years) < 5:\n",
    "    raise ValueError(\"Need at least ~5 years for a proper temporal split.\")\n",
    "\n",
    "test_years  = years[-2:]   # last 2 years → test\n",
    "train_years = years[:-2]   # the rest     → train\n",
    "\n",
    "need_cols = [TARGET] + [f\"{TARGET}_lag{k}\" for k in LAGS]\n",
    "train = wide_lag.loc[(slice(None), train_years), :].dropna(subset=need_cols)\n",
    "test  = wide_lag.loc[(slice(None), test_years),  :].dropna(subset=need_cols)\n",
    "\n",
    "# Features = all indicators except the target + the lagged targets\n",
    "feat_now = [c for c in wide.columns if c != TARGET]\n",
    "feat_lag = [c for c in wide_lag.columns if c.startswith(f\"{TARGET}_lag\")]\n",
    "X_train = train[feat_now + feat_lag].copy()\n",
    "y_train = train[TARGET].copy()\n",
    "X_test  = test[X_train.columns].copy()\n",
    "y_test  = test[TARGET].copy()\n",
    "\n",
    "# Simple missing-value handling: fill with train means\n",
    "col_means = X_train.mean()\n",
    "X_train = X_train.fillna(col_means)\n",
    "X_test  = X_test.fillna(col_means)\n",
    "\n",
    "# ---------- 5) Fit two models ----------\n",
    "# a) Linear regression (scaled)\n",
    "scaler = StandardScaler()\n",
    "Xtr_scaled = scaler.fit_transform(X_train)\n",
    "Xte_scaled = scaler.transform(X_test)\n",
    "lin = LinearRegression().fit(Xtr_scaled, y_train)\n",
    "pred_lin = lin.predict(Xte_scaled)\n",
    "\n",
    "# b) Random Forest (solid baseline for tabular data)\n",
    "rf = RandomForestRegressor(n_estimators=600, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "def report(name, y_true, y_pred):\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{name}: R² = {r2:.3f} | MAE = {mae:.3f}\")\n",
    "    return r2, mae\n",
    "\n",
    "print(\"\\nModel performance (test years):\")\n",
    "r2_lin, mae_lin = report(\"Linear     \", y_test, pred_lin)\n",
    "r2_rf,  mae_rf  = report(\"RandomForest\", y_test, pred_rf)\n",
    "\n",
    "#6) Plots: predicted vs actual + residuals \n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=y_test, y=pred_rf)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"k--\", alpha=0.5)\n",
    "plt.xlabel(\"Actual\"); plt.ylabel(\"Predicted\")\n",
    "plt.title(f\"{TARGET} — RF predictions (test)\")\n",
    "plt.tight_layout(); plt.savefig(OUT_DIR / \"rf_pred_vs_actual.png\", dpi=150); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "resid = y_test - pred_rf\n",
    "sns.histplot(resid, bins=15, kde=True)\n",
    "plt.title(\"Random Forest residuals (test)\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.tight_layout(); plt.savefig(OUT_DIR / \"rf_residuals_hist.png\", dpi=150); plt.show()\n",
    "\n",
    "#  7) Permutation importance \n",
    "perm = permutation_importance(rf, X_test, y_test, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "imp = (pd.DataFrame({\"feature\": X_train.columns, \"importance\": perm.importances_mean})\n",
    "         .sort_values(\"importance\", ascending=False))\n",
    "\n",
    "top20 = imp.head(20)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(data=top20, y=\"feature\", x=\"importance\")\n",
    "plt.title(\"Permutation Importance (RF) — top 20\")\n",
    "plt.tight_layout(); plt.savefig(OUT_DIR / \"rf_perm_importance.png\", dpi=150); plt.show()\n",
    "\n",
    "print(\"\\nTop drivers:\")\n",
    "display(top20.head(10))\n",
    "\n",
    "#  8)  “what-if”: reduce the top driver by 10% \n",
    "if not top20.empty:\n",
    "    main_driver = top20.iloc[0][\"feature\"]\n",
    "    print(f\"\\nWhat-if: reduce '{main_driver}' by 10% on test rows …\")\n",
    "    X_sim = X_test.copy()\n",
    "    X_sim[main_driver] = X_sim[main_driver] * 0.90\n",
    "    pred_sim = rf.predict(X_sim)\n",
    "\n",
    "    # Negative delta = predicted improvement (because lower is better for a mortality rate)\n",
    "    delta = pred_sim - pred_rf\n",
    "    by_state = (pd.DataFrame({\"State\": y_test.index.get_level_values(0), \"Delta\": delta})\n",
    "                  .groupby(\"State\", as_index=False)[\"Delta\"].mean()\n",
    "                  .sort_values(\"Delta\"))\n",
    "\n",
    "    plt.figure(figsize=(9,5))\n",
    "    sns.barplot(data=by_state, x=\"State\", y=\"Delta\")\n",
    "    plt.axhline(0, color=\"k\", lw=1)\n",
    "    plt.title(f\"What-if: 10% drop in '{main_driver}' — change in predicted {TARGET}\")\n",
    "    plt.ylabel(\"Change in predicted rate\")\n",
    "    plt.tight_layout(); plt.savefig(OUT_DIR / \"rf_what_if_driver_minus10.png\", dpi=150); plt.show()\n",
    "\n",
    "#  9) one-step “forecast” demo \n",
    "# Train on all but the latest year; predict the next (latest+1) for each state using lag features.\n",
    "latest_year = wide_lag.index.get_level_values(\"Year\").max()\n",
    "last_rows   = wide_lag.xs(latest_year, level=\"Year\", drop_level=False)\n",
    "last_feats  = last_rows[X_train.columns].fillna(col_means)\n",
    "next_pred   = rf.predict(last_feats)\n",
    "\n",
    "forecast = last_rows.reset_index()[[\"State\", \"Year\"]].copy()\n",
    "forecast[\"Forecast_Year\"] = forecast[\"Year\"] + 1\n",
    "forecast[f\"Predicted_{TARGET}\"] = next_pred\n",
    "\n",
    "print(\"\\nSample one-step forecast (per state/region):\")\n",
    "display(forecast.head(20))\n",
    "\n",
    "forecast.to_csv(OUT_DIR / \"rf_one_step_forecast_next_year.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved files in:\", OUT_DIR.resolve())\n",
    "for f in [\"rf_pred_vs_actual.png\",\n",
    "          \"rf_residuals_hist.png\",\n",
    "          \"rf_perm_importance.png\",\n",
    "          \"rf_what_if_driver_minus10.png\",\n",
    "          \"rf_one_step_forecast_next_year.csv\"]:\n",
    "    print(\" -\", OUT_DIR / f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
